{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "assignment_regression_classification_4.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/spentaur/DS-Unit-2-Regression-Classification/blob/master/module4/assignment_regression_classification_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7IXUfiQ2UKj6",
        "colab_type": "text"
      },
      "source": [
        "Lambda School Data Science, Unit 2: Predictive Modeling\n",
        "\n",
        "# Regression & Classification, Module 4\n",
        "\n",
        "## Assignment\n",
        "\n",
        "- [ ] Watch Aaron Gallant's [video #1](https://www.youtube.com/watch?v=pREaWFli-5I) (12 minutes) & [video #2](https://www.youtube.com/watch?v=bDQgVt4hFgY) (9 minutes) to learn about the mathematics of Logistic Regression.\n",
        "- [ ] Do train/validate/test split with the Tanzania Waterpumps data.\n",
        "- [ ] Do one-hot encoding. (Remember it may not work with high cardinality categoricals.)\n",
        "- [ ] Use scikit-learn for logistic regression.\n",
        "- [ ] Get your validation accuracy score.\n",
        "- [ ] Get and plot your coefficients.\n",
        "- [ ] Submit your predictions to our Kaggle competition. (Go to our Kaggle InClass competition webpage. Use the blue **Submit Predictions** button to upload your CSV file. Or you can use the Kaggle API to submit your predictions.)\n",
        "- [ ] Commit your notebook to your fork of the GitHub repo.\n",
        "\n",
        "> [Do Not Copy-Paste.](https://docs.google.com/document/d/1ubOw9B3Hfip27hF2ZFnW3a3z9xAgrUDRReOEo-FHCVs/edit) You must type each of these exercises in, manually. If you copy and paste, you might as well not even do them. The point of these exercises is to train your hands, your brain, and your mind in how to read, write, and see code. If you copy-paste, you are cheating yourself out of the effectiveness of the lessons.\n",
        "\n",
        "\n",
        "## Stretch Goals\n",
        "\n",
        "### Doing\n",
        "- [ ] Add your own stretch goal(s) !\n",
        "- [ ] Clean the data. For ideas, refer to [The Quartz guide to bad data](https://github.com/Quartz/bad-data-guide),  a \"reference to problems seen in real-world data along with suggestions on how to resolve them.\" One of the issues is [\"Zeros replace missing values.\"](https://github.com/Quartz/bad-data-guide#zeros-replace-missing-values)\n",
        "- [ ] Make exploratory visualizations.\n",
        "- [ ] Do [feature scaling](https://scikit-learn.org/stable/modules/preprocessing.html).\n",
        "- [ ] Try [scikit-learn pipelines](https://scikit-learn.org/stable/modules/compose.html).\n",
        "\n",
        "\n",
        "#### Exploratory visualizations\n",
        "\n",
        "Visualize the relationships between feature(s) and target. I recommend you do this with your training set, after splitting your data. \n",
        "\n",
        "For this problem, you may want to create a new column to represent the target as a number, 0 or 1. For example:\n",
        "\n",
        "```python\n",
        "train['functional'] = (train['status_group']=='functional').astype(int)\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "You can try [Seaborn \"Categorical estimate\" plots](https://seaborn.pydata.org/tutorial/categorical.html) for features with reasonably few unique values. (With too many unique values, the plot is unreadable.)\n",
        "\n",
        "- Categorical features. (If there are too many unique values, you can replace less frequent values with \"OTHER.\")\n",
        "- Numeric features. (If there are too many unique values, you can [bin with pandas cut / qcut functions](https://pandas.pydata.org/pandas-docs/stable/getting_started/basics.html?highlight=qcut#discretization-and-quantiling).)\n",
        "\n",
        "You can try [Seaborn linear model plots](https://seaborn.pydata.org/tutorial/regression.html) with numeric features. For this problem, you may want to use the parameter `logistic=True`\n",
        "\n",
        "You do _not_ need to use Seaborn, but it's nice because it includes confidence intervals to visualize uncertainty.\n",
        "\n",
        "#### High-cardinality categoricals\n",
        "\n",
        "This code from the previous assignment demonstrates how to replace less frequent values with 'OTHER'\n",
        "\n",
        "```python\n",
        "# Reduce cardinality for NEIGHBORHOOD feature ...\n",
        "\n",
        "# Get a list of the top 10 neighborhoods\n",
        "top10 = train['NEIGHBORHOOD'].value_counts()[:10].index\n",
        "\n",
        "# At locations where the neighborhood is NOT in the top 10,\n",
        "# replace the neighborhood with 'OTHER'\n",
        "train.loc[~train['NEIGHBORHOOD'].isin(top10), 'NEIGHBORHOOD'] = 'OTHER'\n",
        "test.loc[~test['NEIGHBORHOOD'].isin(top10), 'NEIGHBORHOOD'] = 'OTHER'\n",
        "```\n",
        "\n",
        "#### Pipelines\n",
        "\n",
        "[Scikit-Learn User Guide](https://scikit-learn.org/stable/modules/compose.html) explains why pipelines are useful, and demonstrates how to use them:\n",
        "\n",
        "> Pipeline can be used to chain multiple estimators into one. This is useful as there is often a fixed sequence of steps in processing the data, for example feature selection, normalization and classification. Pipeline serves multiple purposes here:\n",
        "> - **Convenience and encapsulation.** You only have to call fit and predict once on your data to fit a whole sequence of estimators.\n",
        "> - **Joint parameter selection.** You can grid search over parameters of all estimators in the pipeline at once.\n",
        "> - **Safety.** Pipelines help avoid leaking statistics from your test data into the trained model in cross-validation, by ensuring that the same samples are used to train the transformers and predictors.\n",
        "\n",
        "### Reading\n",
        "- [ ] [How (and why) to create a good validation set](https://www.fast.ai/2017/11/13/validation-sets/)\n",
        "- [ ] [Always start with a stupid model, no exceptions](https://blog.insightdatascience.com/always-start-with-a-stupid-model-no-exceptions-3a22314b9aaa)\n",
        "- [ ] [Statistical Modeling: The Two Cultures](https://projecteuclid.org/download/pdf_1/euclid.ss/1009213726)\n",
        "- [ ] [_An Introduction to Statistical Learning_](http://faculty.marshall.usc.edu/gareth-james/ISL/ISLR%20Seventh%20Printing.pdf), Chapters 1-3, for more math & theory, but in an accessible, readable way (without an excessive amount of formulas or academic pre-requisites).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9eSnDYhUGD7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "fae20ed0-c543-4e30-a6f6-f7bca31c1af6"
      },
      "source": [
        "# If you're in Colab...\n",
        "import os, sys\n",
        "in_colab = 'google.colab' in sys.modules\n",
        "\n",
        "if in_colab:\n",
        "    # Install required python packages:\n",
        "    # category_encoders, version >= 2.0\n",
        "    # pandas-profiling, version >= 2.0\n",
        "    # plotly, version >= 4.0\n",
        "    !pip install --upgrade category_encoders pandas-profiling plotly\n",
        "    \n",
        "    # Pull files from Github repo\n",
        "    os.chdir('/content')\n",
        "    !git init .\n",
        "    !git remote add origin https://github.com/LambdaSchool/DS-Unit-2-Regression-Classification.git\n",
        "    !git pull origin master\n",
        "    \n",
        "    # Change into directory for module\n",
        "    os.chdir('module4')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting category_encoders\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6e/a1/f7a22f144f33be78afeb06bfa78478e8284a64263a3c09b1ef54e673841e/category_encoders-2.0.0-py2.py3-none-any.whl (87kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 2.2MB/s \n",
            "\u001b[?25hCollecting pandas-profiling\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2c/2f/aae19e2173c10a9bb7fee5f5cad35dbe53a393960fc91abc477dcc4661e8/pandas-profiling-2.3.0.tar.gz (127kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 2.3MB/s \n",
            "\u001b[?25hRequirement already up-to-date: plotly in /usr/local/lib/python3.6/dist-packages (4.1.1)\n",
            "Requirement already satisfied, skipping upgrade: scikit-learn>=0.20.0 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (0.21.3)\n",
            "Requirement already satisfied, skipping upgrade: scipy>=0.19.0 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (1.3.1)\n",
            "Requirement already satisfied, skipping upgrade: pandas>=0.21.1 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (0.24.2)\n",
            "Requirement already satisfied, skipping upgrade: statsmodels>=0.6.1 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (0.10.1)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (1.16.5)\n",
            "Requirement already satisfied, skipping upgrade: patsy>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (0.5.1)\n",
            "Requirement already satisfied, skipping upgrade: matplotlib>=1.4 in /usr/local/lib/python3.6/dist-packages (from pandas-profiling) (3.0.3)\n",
            "Requirement already satisfied, skipping upgrade: jinja2>=2.8 in /usr/local/lib/python3.6/dist-packages (from pandas-profiling) (2.10.1)\n",
            "Requirement already satisfied, skipping upgrade: missingno>=0.4.2 in /usr/local/lib/python3.6/dist-packages (from pandas-profiling) (0.4.2)\n",
            "Collecting htmlmin>=0.1.12 (from pandas-profiling)\n",
            "  Downloading https://files.pythonhosted.org/packages/b3/e7/fcd59e12169de19f0131ff2812077f964c6b960e7c09804d30a7bf2ab461/htmlmin-0.1.12.tar.gz\n",
            "Collecting phik>=0.9.8 (from pandas-profiling)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/45/ad/24a16fa4ba612fb96a3c4bb115a5b9741483f53b66d3d3afd987f20fa227/phik-0.9.8-py3-none-any.whl (606kB)\n",
            "\u001b[K     |████████████████████████████████| 614kB 2.1MB/s \n",
            "\u001b[?25hCollecting confuse>=1.0.0 (from pandas-profiling)\n",
            "  Downloading https://files.pythonhosted.org/packages/4c/6f/90e860cba937c174d8b3775729ccc6377eb91f52ad4eeb008e7252a3646d/confuse-1.0.0.tar.gz\n",
            "Requirement already satisfied, skipping upgrade: astropy in /usr/local/lib/python3.6/dist-packages (from pandas-profiling) (3.0.5)\n",
            "Requirement already satisfied, skipping upgrade: retrying>=1.3.3 in /usr/local/lib/python3.6/dist-packages (from plotly) (1.3.3)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from plotly) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.20.0->category_encoders) (0.13.2)\n",
            "Requirement already satisfied, skipping upgrade: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas>=0.21.1->category_encoders) (2018.9)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.5.0 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.21.1->category_encoders) (2.5.3)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.4->pandas-profiling) (2.4.2)\n",
            "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.4->pandas-profiling) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.4->pandas-profiling) (0.10.0)\n",
            "Requirement already satisfied, skipping upgrade: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2>=2.8->pandas-profiling) (1.1.1)\n",
            "Requirement already satisfied, skipping upgrade: seaborn in /usr/local/lib/python3.6/dist-packages (from missingno>=0.4.2->pandas-profiling) (0.9.0)\n",
            "Requirement already satisfied, skipping upgrade: numba>=0.38.1 in /usr/local/lib/python3.6/dist-packages (from phik>=0.9.8->pandas-profiling) (0.40.1)\n",
            "Requirement already satisfied, skipping upgrade: nbconvert>=5.3.1 in /usr/local/lib/python3.6/dist-packages (from phik>=0.9.8->pandas-profiling) (5.6.0)\n",
            "Collecting pytest>=4.0.2 (from phik>=0.9.8->pandas-profiling)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2f/19/d5f71752f71451ccc5ed5f6739e9da4a235f38783fdaf3629cae41b2ca7b/pytest-5.1.2-py3-none-any.whl (224kB)\n",
            "\u001b[K     |████████████████████████████████| 225kB 2.4MB/s \n",
            "\u001b[?25hCollecting pytest-pylint>=0.13.0 (from phik>=0.9.8->pandas-profiling)\n",
            "  Downloading https://files.pythonhosted.org/packages/64/dc/6f35f114844fb12e38d60c4f3d2441a55baff7043ad4e013777dff55746c/pytest_pylint-0.14.1-py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: jupyter-client>=5.2.3 in /usr/local/lib/python3.6/dist-packages (from phik>=0.9.8->pandas-profiling) (5.3.1)\n",
            "Requirement already satisfied, skipping upgrade: pyyaml in /usr/local/lib/python3.6/dist-packages (from confuse>=1.0.0->pandas-profiling) (3.13)\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib>=1.4->pandas-profiling) (41.2.0)\n",
            "Requirement already satisfied, skipping upgrade: llvmlite>=0.25.0dev0 in /usr/local/lib/python3.6/dist-packages (from numba>=0.38.1->phik>=0.9.8->pandas-profiling) (0.29.0)\n",
            "Requirement already satisfied, skipping upgrade: nbformat>=4.4 in /usr/local/lib/python3.6/dist-packages (from nbconvert>=5.3.1->phik>=0.9.8->pandas-profiling) (4.4.0)\n",
            "Requirement already satisfied, skipping upgrade: defusedxml in /usr/local/lib/python3.6/dist-packages (from nbconvert>=5.3.1->phik>=0.9.8->pandas-profiling) (0.6.0)\n",
            "Requirement already satisfied, skipping upgrade: testpath in /usr/local/lib/python3.6/dist-packages (from nbconvert>=5.3.1->phik>=0.9.8->pandas-profiling) (0.4.2)\n",
            "Requirement already satisfied, skipping upgrade: bleach in /usr/local/lib/python3.6/dist-packages (from nbconvert>=5.3.1->phik>=0.9.8->pandas-profiling) (3.1.0)\n",
            "Requirement already satisfied, skipping upgrade: entrypoints>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from nbconvert>=5.3.1->phik>=0.9.8->pandas-profiling) (0.3)\n",
            "Requirement already satisfied, skipping upgrade: jupyter-core in /usr/local/lib/python3.6/dist-packages (from nbconvert>=5.3.1->phik>=0.9.8->pandas-profiling) (4.5.0)\n",
            "Requirement already satisfied, skipping upgrade: pygments in /usr/local/lib/python3.6/dist-packages (from nbconvert>=5.3.1->phik>=0.9.8->pandas-profiling) (2.1.3)\n",
            "Requirement already satisfied, skipping upgrade: pandocfilters>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert>=5.3.1->phik>=0.9.8->pandas-profiling) (1.4.2)\n",
            "Requirement already satisfied, skipping upgrade: traitlets>=4.2 in /usr/local/lib/python3.6/dist-packages (from nbconvert>=5.3.1->phik>=0.9.8->pandas-profiling) (4.3.2)\n",
            "Requirement already satisfied, skipping upgrade: mistune<2,>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert>=5.3.1->phik>=0.9.8->pandas-profiling) (0.8.4)\n",
            "Requirement already satisfied, skipping upgrade: more-itertools>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=4.0.2->phik>=0.9.8->pandas-profiling) (7.2.0)\n",
            "Requirement already satisfied, skipping upgrade: py>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=4.0.2->phik>=0.9.8->pandas-profiling) (1.8.0)\n",
            "Collecting pluggy<1.0,>=0.12 (from pytest>=4.0.2->phik>=0.9.8->pandas-profiling)\n",
            "  Downloading https://files.pythonhosted.org/packages/92/c7/48439f7d5fd6bddb4c04b850bb862b42e3e2b98570040dfaf68aedd8114b/pluggy-0.13.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=4.0.2->phik>=0.9.8->pandas-profiling) (19.1.0)\n",
            "Requirement already satisfied, skipping upgrade: packaging in /usr/local/lib/python3.6/dist-packages (from pytest>=4.0.2->phik>=0.9.8->pandas-profiling) (19.1)\n",
            "Requirement already satisfied, skipping upgrade: atomicwrites>=1.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=4.0.2->phik>=0.9.8->pandas-profiling) (1.3.0)\n",
            "Requirement already satisfied, skipping upgrade: importlib-metadata>=0.12; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from pytest>=4.0.2->phik>=0.9.8->pandas-profiling) (0.20)\n",
            "Requirement already satisfied, skipping upgrade: wcwidth in /usr/local/lib/python3.6/dist-packages (from pytest>=4.0.2->phik>=0.9.8->pandas-profiling) (0.1.7)\n",
            "Collecting pylint>=1.4.5 (from pytest-pylint>=0.13.0->phik>=0.9.8->pandas-profiling)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/60/c2/b3f73f4ac008bef6e75bca4992f3963b3f85942e0277237721ef1c151f0d/pylint-2.3.1-py3-none-any.whl (765kB)\n",
            "\u001b[K     |████████████████████████████████| 768kB 1.8MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: pyzmq>=13 in /usr/local/lib/python3.6/dist-packages (from jupyter-client>=5.2.3->phik>=0.9.8->pandas-profiling) (17.0.0)\n",
            "Requirement already satisfied, skipping upgrade: tornado>=4.1 in /usr/local/lib/python3.6/dist-packages (from jupyter-client>=5.2.3->phik>=0.9.8->pandas-profiling) (4.5.3)\n",
            "Requirement already satisfied, skipping upgrade: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from nbformat>=4.4->nbconvert>=5.3.1->phik>=0.9.8->pandas-profiling) (0.2.0)\n",
            "Requirement already satisfied, skipping upgrade: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbformat>=4.4->nbconvert>=5.3.1->phik>=0.9.8->pandas-profiling) (2.6.0)\n",
            "Requirement already satisfied, skipping upgrade: webencodings in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert>=5.3.1->phik>=0.9.8->pandas-profiling) (0.5.1)\n",
            "Requirement already satisfied, skipping upgrade: decorator in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2->nbconvert>=5.3.1->phik>=0.9.8->pandas-profiling) (4.4.0)\n",
            "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.12; python_version < \"3.8\"->pytest>=4.0.2->phik>=0.9.8->pandas-profiling) (0.6.0)\n",
            "Collecting isort<5,>=4.2.5 (from pylint>=1.4.5->pytest-pylint>=0.13.0->phik>=0.9.8->pandas-profiling)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/b0/c121fd1fa3419ea9bfd55c7f9c4fedfec5143208d8c7ad3ce3db6c623c21/isort-4.3.21-py2.py3-none-any.whl (42kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 3.7MB/s \n",
            "\u001b[?25hCollecting astroid<3,>=2.2.0 (from pylint>=1.4.5->pytest-pylint>=0.13.0->phik>=0.9.8->pandas-profiling)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d5/ad/7221a62a2dbce5c3b8c57fd18e1052c7331adc19b3f27f1561aa6e620db2/astroid-2.2.5-py3-none-any.whl (193kB)\n",
            "\u001b[K     |████████████████████████████████| 194kB 2.1MB/s \n",
            "\u001b[?25hCollecting mccabe<0.7,>=0.6 (from pylint>=1.4.5->pytest-pylint>=0.13.0->phik>=0.9.8->pandas-profiling)\n",
            "  Downloading https://files.pythonhosted.org/packages/87/89/479dc97e18549e21354893e4ee4ef36db1d237534982482c3681ee6e7b57/mccabe-0.6.1-py2.py3-none-any.whl\n",
            "Collecting typed-ast>=1.3.0; implementation_name == \"cpython\" (from astroid<3,>=2.2.0->pylint>=1.4.5->pytest-pylint>=0.13.0->phik>=0.9.8->pandas-profiling)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/31/d3/9d1802c161626d0278bafb1ffb32f76b9d01e123881bbf9d91e8ccf28e18/typed_ast-1.4.0-cp36-cp36m-manylinux1_x86_64.whl (736kB)\n",
            "\u001b[K     |████████████████████████████████| 737kB 1.8MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: wrapt in /usr/local/lib/python3.6/dist-packages (from astroid<3,>=2.2.0->pylint>=1.4.5->pytest-pylint>=0.13.0->phik>=0.9.8->pandas-profiling) (1.11.2)\n",
            "Collecting lazy-object-proxy (from astroid<3,>=2.2.0->pylint>=1.4.5->pytest-pylint>=0.13.0->phik>=0.9.8->pandas-profiling)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0e/26/534a6d32572a9dbca11619321535c0a7ab34688545d9d67c2c204b9e3a3d/lazy_object_proxy-1.4.2-cp36-cp36m-manylinux1_x86_64.whl (49kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 2.5MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pandas-profiling, htmlmin, confuse\n",
            "  Building wheel for pandas-profiling (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pandas-profiling: filename=pandas_profiling-2.3.0-py2.py3-none-any.whl size=145035 sha256=9a3658d10169245b22918c11bc6a456227bcd8b1442a034b04d07c484f20788a\n",
            "  Stored in directory: /root/.cache/pip/wheels/ce/c7/f1/dbfef4848ebb048cb1d4a22d1ed0c62d8ff2523747235e19fe\n",
            "  Building wheel for htmlmin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for htmlmin: filename=htmlmin-0.1.12-cp36-none-any.whl size=27084 sha256=cb954bae2c3c1e37be6dbd5453413af22820b6d420e1250c5cd1317a774b0b24\n",
            "  Stored in directory: /root/.cache/pip/wheels/43/07/ac/7c5a9d708d65247ac1f94066cf1db075540b85716c30255459\n",
            "  Building wheel for confuse (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for confuse: filename=confuse-1.0.0-cp36-none-any.whl size=17486 sha256=04f06bdfb643d6de23cb8e74f32386c0a113b7f73ec3803e7aced4a0523f59e0\n",
            "  Stored in directory: /root/.cache/pip/wheels/b0/b2/96/2074eee7dbf7b7df69d004c9b6ac4e32dad04fb7666cf943bd\n",
            "Successfully built pandas-profiling htmlmin confuse\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: category-encoders, htmlmin, pluggy, pytest, isort, typed-ast, lazy-object-proxy, astroid, mccabe, pylint, pytest-pylint, phik, confuse, pandas-profiling\n",
            "  Found existing installation: pluggy 0.7.1\n",
            "    Uninstalling pluggy-0.7.1:\n",
            "      Successfully uninstalled pluggy-0.7.1\n",
            "  Found existing installation: pytest 3.6.4\n",
            "    Uninstalling pytest-3.6.4:\n",
            "      Successfully uninstalled pytest-3.6.4\n",
            "  Found existing installation: pandas-profiling 1.4.1\n",
            "    Uninstalling pandas-profiling-1.4.1:\n",
            "      Successfully uninstalled pandas-profiling-1.4.1\n",
            "Successfully installed astroid-2.2.5 category-encoders-2.0.0 confuse-1.0.0 htmlmin-0.1.12 isort-4.3.21 lazy-object-proxy-1.4.2 mccabe-0.6.1 pandas-profiling-2.3.0 phik-0.9.8 pluggy-0.13.0 pylint-2.3.1 pytest-5.1.2 pytest-pylint-0.14.1 typed-ast-1.4.0\n",
            "Initialized empty Git repository in /content/.git/\n",
            "remote: Enumerating objects: 104, done.\u001b[K\n",
            "remote: Total 104 (delta 0), reused 0 (delta 0), pack-reused 104\u001b[K\n",
            "Receiving objects: 100% (104/104), 17.31 MiB | 20.31 MiB/s, done.\n",
            "Resolving deltas: 100% (41/41), done.\n",
            "From https://github.com/LambdaSchool/DS-Unit-2-Regression-Classification\n",
            " * branch            master     -> FETCH_HEAD\n",
            " * [new branch]      master     -> origin/master\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ipBYS77PUwNR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Ignore this Numpy warning when using Plotly Express:\n",
        "# FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.\n",
        "import warnings\n",
        "warnings.filterwarnings(action='ignore', category=FutureWarning, module='numpy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJBD4ruICm1m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "train_features = pd.read_csv('../data/tanzania/train_features.csv')\n",
        "train_labels = pd.read_csv('../data/tanzania/train_labels.csv')\n",
        "test_features = pd.read_csv('../data/tanzania/test_features.csv')\n",
        "sample_submission = pd.read_csv('../data/tanzania/sample_submission.csv')\n",
        "\n",
        "assert train_features.shape == (59400, 40)\n",
        "assert train_labels.shape == (59400, 2)\n",
        "assert test_features.shape == (14358, 40)\n",
        "assert sample_submission.shape == (14358, 2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OgGPYHAgCDhr",
        "colab_type": "text"
      },
      "source": [
        "# feature enginering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kRZ3xuQ-DHFV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_with_labels = train_features.merge(train_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kMs2FMe1ekEe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import pandas_profiling\n",
        "# train_features.profile_report()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-UNsmRxptPGH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "extraction = ['extraction_type',\n",
        "              'extraction_type_group',\n",
        "              'extraction_type_class']\n",
        "\n",
        "management = ['management', 'management_group']\n",
        "\n",
        "payment = ['payment', 'payment_type']\n",
        "\n",
        "quality = ['quantity',\n",
        "           'quantity_group']\n",
        "\n",
        "region = ['region',\n",
        "          'region_code']\n",
        "\n",
        "source = ['source', 'source_type', 'source_class']\n",
        "\n",
        "waterpoint = ['waterpoint_type', 'waterpoint_type_group']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cfdOh7qZuU_i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 869
        },
        "outputId": "f1a879c6-916c-42ca-d7e1-a89a84eccc44"
      },
      "source": [
        "for cat in extraction:\n",
        "    print(pd.crosstab(train_with_labels[cat], train_with_labels['status_group'], normalize='index').sort_values('functional', ascending=False))\n",
        "\n",
        "\n",
        "# let's go with first\n",
        "# extraction_type"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "status_group               functional  functional needs repair  non functional\n",
            "extraction_type                                                               \n",
            "afridev                      0.677966                 0.023729        0.298305\n",
            "nira/tanira                  0.664827                 0.078612        0.256561\n",
            "other - rope pump            0.649667                 0.037694        0.312639\n",
            "india mark ii                0.603333                 0.032917        0.363750\n",
            "gravity                      0.599253                 0.100859        0.299888\n",
            "swn 80                       0.569482                 0.057766        0.372752\n",
            "submersible                  0.551217                 0.047649        0.401134\n",
            "other - swn 81               0.524017                 0.030568        0.445415\n",
            "cemo                         0.500000                 0.100000        0.400000\n",
            "ksb                          0.496820                 0.018375        0.484806\n",
            "walimi                       0.479167                 0.250000        0.270833\n",
            "india mark iii               0.448980                 0.010204        0.540816\n",
            "windmill                     0.427350                 0.059829        0.512821\n",
            "mono                         0.377661                 0.045026        0.577312\n",
            "other - play pump            0.341176                 0.011765        0.647059\n",
            "climax                       0.250000                 0.000000        0.750000\n",
            "other                        0.160031                 0.032037        0.807932\n",
            "other - mkulima/shinyanga    0.000000                 0.000000        1.000000\n",
            "status_group           functional  functional needs repair  non functional\n",
            "extraction_type_group                                                     \n",
            "afridev                  0.677966                 0.023729        0.298305\n",
            "nira/tanira              0.664827                 0.078612        0.256561\n",
            "rope pump                0.649667                 0.037694        0.312639\n",
            "india mark ii            0.603333                 0.032917        0.363750\n",
            "gravity                  0.599253                 0.100859        0.299888\n",
            "swn 80                   0.569482                 0.057766        0.372752\n",
            "submersible              0.538760                 0.040945        0.420295\n",
            "other handpump           0.472527                 0.054945        0.472527\n",
            "india mark iii           0.448980                 0.010204        0.540816\n",
            "other motorpump          0.434426                 0.073770        0.491803\n",
            "wind-powered             0.427350                 0.059829        0.512821\n",
            "mono                     0.377661                 0.045026        0.577312\n",
            "other                    0.160031                 0.032037        0.807932\n",
            "status_group           functional  functional needs repair  non functional\n",
            "extraction_type_class                                                     \n",
            "rope pump                0.649667                 0.037694        0.312639\n",
            "handpump                 0.630469                 0.060464        0.309067\n",
            "gravity                  0.599253                 0.100859        0.299888\n",
            "submersible              0.538760                 0.040945        0.420295\n",
            "wind-powered             0.427350                 0.059829        0.512821\n",
            "motorpump                0.379980                 0.046200        0.573820\n",
            "other                    0.160031                 0.032037        0.807932\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hu345djNu0SV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "19c516b2-b7fb-436b-c4d1-a365e4df78e8"
      },
      "source": [
        "for cat in management:\n",
        "    print(pd.crosstab(train_with_labels[cat], train_with_labels['status_group'], normalize='index').sort_values('functional', ascending=False))\n",
        "\n",
        "# first again\n",
        "# management"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "status_group      functional  functional needs repair  non functional\n",
            "management                                                           \n",
            "private operator    0.748858                 0.022324        0.228818\n",
            "water board         0.739857                 0.090351        0.169792\n",
            "wua                 0.690730                 0.080868        0.228402\n",
            "wug                 0.599540                 0.099002        0.301458\n",
            "other               0.598341                 0.065166        0.336493\n",
            "trust               0.589744                 0.076923        0.333333\n",
            "parastatal          0.576923                 0.119344        0.303733\n",
            "vwc                 0.504234                 0.068902        0.426864\n",
            "water authority     0.493363                 0.057522        0.449115\n",
            "unknown             0.399287                 0.048128        0.552585\n",
            "company             0.389781                 0.021898        0.588321\n",
            "other - school      0.232323                 0.010101        0.757576\n",
            "status_group      functional  functional needs repair  non functional\n",
            "management_group                                                     \n",
            "commercial          0.614349                 0.032161        0.353491\n",
            "parastatal          0.576923                 0.119344        0.303733\n",
            "other               0.559915                 0.059385        0.380700\n",
            "user-group          0.538236                 0.074414        0.387350\n",
            "unknown             0.399287                 0.048128        0.552585\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UIfiSfSGu8TJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 366
        },
        "outputId": "3f3d01df-b242-4c3e-d640-d97fc59b7ad0"
      },
      "source": [
        "for cat in payment:\n",
        "    print(pd.crosstab(train_with_labels[cat], train_with_labels['status_group'], normalize='index').sort_values('functional', ascending=False))\n",
        "\n",
        "# i'll just have to try with each one and see which one is better"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "status_group           functional  functional needs repair  non functional\n",
            "payment                                                                   \n",
            "pay annually             0.752334                 0.067820        0.179846\n",
            "pay per bucket           0.677796                 0.045520        0.276683\n",
            "pay monthly              0.660482                 0.111687        0.227831\n",
            "pay when scheme fails    0.620593                 0.070772        0.308636\n",
            "other                    0.579696                 0.111954        0.308349\n",
            "never pay                0.448911                 0.075233        0.475856\n",
            "unknown                  0.432512                 0.052961        0.514527\n",
            "status_group  functional  functional needs repair  non functional\n",
            "payment_type                                                     \n",
            "annually        0.752334                 0.067820        0.179846\n",
            "per bucket      0.677796                 0.045520        0.276683\n",
            "monthly         0.660482                 0.111687        0.227831\n",
            "on failure      0.620593                 0.070772        0.308636\n",
            "other           0.579696                 0.111954        0.308349\n",
            "never pay       0.448911                 0.075233        0.475856\n",
            "unknown         0.432512                 0.052961        0.514527\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TabyoGB0vC1U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "d30cad32-52bc-412a-a0b6-0e826b34c2ae"
      },
      "source": [
        "all(train_with_labels['payment'] == train_with_labels['payment_type'])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BER0Iw7SvPU_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 288
        },
        "outputId": "09a5a0cb-7b99-4fc2-a760-52563e62e01f"
      },
      "source": [
        "for cat in quality:\n",
        "    print(pd.crosstab(train_with_labels[cat], train_with_labels['status_group'], normalize='index').sort_values('functional', ascending=False))\n",
        "\n",
        "# repeat just use quality"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "status_group  functional  functional needs repair  non functional\n",
            "quantity                                                         \n",
            "enough          0.652323                 0.072320        0.275357\n",
            "seasonal        0.574074                 0.102716        0.323210\n",
            "insufficient    0.523234                 0.095842        0.380924\n",
            "unknown         0.269962                 0.017744        0.712294\n",
            "dry             0.025136                 0.005924        0.968940\n",
            "status_group    functional  functional needs repair  non functional\n",
            "quantity_group                                                     \n",
            "enough            0.652323                 0.072320        0.275357\n",
            "seasonal          0.574074                 0.102716        0.323210\n",
            "insufficient      0.523234                 0.095842        0.380924\n",
            "unknown           0.269962                 0.017744        0.712294\n",
            "dry               0.025136                 0.005924        0.968940\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77xev4QvvYIp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "f3c5e24e-f01e-42dd-de16-d1dd269622da"
      },
      "source": [
        "all(train_with_labels['quantity'] == train_with_labels['quantity_group'])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hOUFBt50vhnr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "145ecf0e-edb3-4b07-c84e-4d99afcfc1d8"
      },
      "source": [
        "for cat in region:\n",
        "    print(pd.crosstab(train_with_labels[cat], train_with_labels['status_group'], normalize='index').sort_values('functional', ascending=False))\n",
        "\n",
        "# region code, but maybe map so it's linear?"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "status_group   functional  functional needs repair  non functional\n",
            "region                                                            \n",
            "Iringa           0.782206                 0.023234        0.194560\n",
            "Arusha           0.684776                 0.052239        0.262985\n",
            "Manyara          0.623500                 0.060644        0.315856\n",
            "Kilimanjaro      0.602877                 0.073533        0.323590\n",
            "Pwani            0.590512                 0.013662        0.395825\n",
            "Dar es Salaam    0.572671                 0.003727        0.423602\n",
            "Tanga            0.563801                 0.028661        0.407538\n",
            "Ruvuma           0.560606                 0.062121        0.377273\n",
            "Shinyanga        0.559815                 0.127459        0.312726\n",
            "Morogoro         0.528957                 0.074888        0.396156\n",
            "Kagera           0.520808                 0.091677        0.387515\n",
            "Mbeya            0.499892                 0.108644        0.391464\n",
            "Mwanza           0.484204                 0.058994        0.456802\n",
            "Kigoma           0.484020                 0.214134        0.301847\n",
            "Singida          0.483039                 0.061156        0.455805\n",
            "Dodoma           0.458428                 0.094957        0.446615\n",
            "Mara             0.449975                 0.030472        0.519553\n",
            "Tabora           0.432874                 0.022971        0.544155\n",
            "Rukwa            0.391040                 0.074668        0.534292\n",
            "Mtwara           0.302890                 0.072832        0.624277\n",
            "Lindi            0.297542                 0.060155        0.642303\n",
            "status_group  functional  functional needs repair  non functional\n",
            "region_code                                                      \n",
            "24              0.969325                 0.003067        0.027607\n",
            "11              0.781698                 0.023208        0.195094\n",
            "6               0.662523                 0.009944        0.327533\n",
            "2               0.654101                 0.057540        0.288360\n",
            "21              0.623500                 0.060644        0.315856\n",
            "3               0.602877                 0.073533        0.323590\n",
            "7               0.572671                 0.003727        0.423602\n",
            "10              0.560606                 0.062121        0.377273\n",
            "4               0.560287                 0.029049        0.410665\n",
            "17              0.560168                 0.127320        0.312512\n",
            "5               0.531436                 0.074257        0.394307\n",
            "18              0.520156                 0.091456        0.388387\n",
            "12              0.499892                 0.108644        0.391464\n",
            "16              0.484020                 0.214134        0.301847\n",
            "13              0.483039                 0.061156        0.455805\n",
            "19              0.481785                 0.058418        0.459797\n",
            "60              0.478049                 0.019512        0.502439\n",
            "1               0.458428                 0.094957        0.446615\n",
            "99              0.451537                 0.016548        0.531915\n",
            "20              0.449975                 0.030472        0.519553\n",
            "14              0.435574                 0.023749        0.540677\n",
            "15              0.391040                 0.074668        0.534292\n",
            "9               0.356410                 0.053846        0.589744\n",
            "80              0.348950                 0.063005        0.588045\n",
            "90              0.211559                 0.106870        0.681570\n",
            "8               0.086667                 0.050000        0.863333\n",
            "40              0.000000                 0.000000        1.000000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H3Ohe2XQvp7l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        },
        "outputId": "61867b4c-bdc6-47c0-85f6-7f95ba96ab9d"
      },
      "source": [
        "for cat in source:\n",
        "    print(pd.crosstab(train_with_labels[cat], train_with_labels['status_group'], normalize='index').sort_values('functional', ascending=False))\n",
        "\n",
        "# go with source"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "status_group          functional  functional needs repair  non functional\n",
            "source                                                                   \n",
            "spring                  0.622290                 0.074966        0.302744\n",
            "rainwater harvesting    0.603922                 0.136819        0.259259\n",
            "other                   0.594340                 0.004717        0.400943\n",
            "hand dtw                0.568650                 0.019451        0.411899\n",
            "river                   0.568560                 0.127029        0.304411\n",
            "shallow well            0.494769                 0.056883        0.448348\n",
            "machine dbh             0.489571                 0.044334        0.466095\n",
            "unknown                 0.484848                 0.060606        0.454545\n",
            "dam                     0.385671                 0.036585        0.577744\n",
            "lake                    0.211765                 0.015686        0.772549\n",
            "status_group          functional  functional needs repair  non functional\n",
            "source_type                                                              \n",
            "spring                  0.622290                 0.074966        0.302744\n",
            "rainwater harvesting    0.603922                 0.136819        0.259259\n",
            "other                   0.568345                 0.017986        0.413669\n",
            "river/lake              0.542257                 0.118820        0.338923\n",
            "borehole                0.495355                 0.042514        0.462131\n",
            "shallow well            0.494769                 0.056883        0.448348\n",
            "dam                     0.385671                 0.036585        0.577744\n",
            "status_group  functional  functional needs repair  non functional\n",
            "source_class                                                     \n",
            "unknown         0.568345                 0.017986        0.413669\n",
            "surface         0.545168                 0.117872        0.336960\n",
            "groundwater     0.542320                 0.059855        0.397825\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oe0w7dkOv5IA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 385
        },
        "outputId": "3c4a22b0-3efd-48e3-bd5c-0b6afdb5406e"
      },
      "source": [
        "for cat in waterpoint:\n",
        "    print(pd.crosstab(train_with_labels[cat], train_with_labels['status_group'], normalize='index').sort_values('functional', ascending=False))\n",
        "\n",
        "# waterpoint_type"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "status_group                 functional  ...  non functional\n",
            "waterpoint_type                          ...                \n",
            "dam                            0.857143  ...        0.142857\n",
            "cattle trough                  0.724138  ...        0.258621\n",
            "improved spring                0.718112  ...        0.173469\n",
            "communal standpipe             0.621485  ...        0.299278\n",
            "hand pump                      0.617852  ...        0.323307\n",
            "communal standpipe multiple    0.366213  ...        0.527609\n",
            "other                          0.131661  ...        0.822414\n",
            "\n",
            "[7 rows x 3 columns]\n",
            "status_group           functional  functional needs repair  non functional\n",
            "waterpoint_type_group                                                     \n",
            "dam                      0.857143                 0.000000        0.142857\n",
            "cattle trough            0.724138                 0.017241        0.258621\n",
            "improved spring          0.718112                 0.108418        0.173469\n",
            "hand pump                0.617852                 0.058840        0.323307\n",
            "communal standpipe       0.576491                 0.083986        0.339523\n",
            "other                    0.131661                 0.045925        0.822414\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6AHKzfjqsfWg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 288
        },
        "outputId": "19671b5f-4818-431c-ef30-324ffb98c914"
      },
      "source": [
        "# columns to drop\n",
        "drop = [\n",
        "\n",
        "        # kept\n",
        "\n",
        "        # # low cardinality\n",
        "        # 'basin', #                keep because low cardinality\n",
        "        # 'quality_group', #        keep because low cardinality\n",
        "        # 'quantity', #             keep because low cardinality\n",
        "        # 'scheme_management', #    keep because low cardinality\n",
        "        # 'water_quality', #        keep because low cardinality\n",
        "        \n",
        "        # # think it was better than alternatives\n",
        "        # 'extraction_type', #      dont drop becauase i think this is the most use full of the extraction_type ones\n",
        "        # 'management', #           keep becuase i thought it was more useful than management_group\n",
        "        # 'payment', #              keep becuase i don't think there's much of a difference between payment, and payment_type\n",
        "        # 'region_code', #          keep becuase i prefered over region\n",
        "        # 'source', #               keep because prefered to source_class, source_type\n",
        "        # 'waterpoint_type', #      keep because prefered over waterpoint_type_group\n",
        "\n",
        "        # # kept because number\n",
        "        # 'district_code', #        keep because numeric\n",
        "        # 'gps_height', #           keep because number and i think there's a relationship\n",
        "\n",
        "        # dropped\n",
        "\n",
        "        # dates\n",
        "        'construction_year', #      drop because has missing and is date\n",
        "        'date_recorded', #          drop because date\n",
        "\n",
        "        # had alternatives\n",
        "        'extraction_type_class', #  didn't think was as useful as extraction_type\n",
        "        'extraction_type_group', #  same with class \n",
        "        'management_group', #       drop because i prefered management\n",
        "        'payment_type', #           drop because payment is kinda the same thing\n",
        "        'region', #                 drop becuase i prefered region code\n",
        "        'waterpoint_type_group', #  drop because prefer waterpoint_type\n",
        "        'source_class', #           drop because source is better\n",
        "        'source_type', #            drop because source is better\n",
        "\n",
        "        # useless\n",
        "        'id', #                     drop because doesn't mean anything\n",
        "        'latitude', #               doesn't mean anything\n",
        "        'longitude', #              same as latitude\n",
        "        'recorded_by', #            drop because it's only 1 value\n",
        "        'quantity_group', #         drop because just a repeat of quatity\n",
        "        'permit', #                 drop because missing values, 5%, and i dont think it would add anything, didn't notice a relationship\n",
        "        'public_meeting', #         drop because missing values, 5%, and too many trues\n",
        "        'population', #             drop because too many 0 values, which i assume are missing?\n",
        "        'amount_tsh', #             drop becuase too many 0, so data is too skewed\n",
        "        'num_private', #            drop because too many 0\n",
        "\n",
        "        # too many missing\n",
        "        'scheme_name', #            drop because too many missing 47%\n",
        "\n",
        "        # high cardinality\n",
        "        'wpt_name', #               drop because high cardinality\n",
        "        'subvillage', #             drop because too high cardinality\n",
        "        'ward', #                   drop because too high cardinality\n",
        "        'funder', #                 drop becuase high cardinality and missing values, 6%\n",
        "        # 'installer', #              same as funder, too many values and missing values, 6%\n",
        "        'lga', #                    drop because too many values, maybe could encode somehow\n",
        "        ]\n",
        "\n",
        "features = train_features.drop(drop, axis=1)\n",
        "features.dtypes.sort_values()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "gps_height            int64\n",
              "region_code           int64\n",
              "district_code         int64\n",
              "basin                object\n",
              "scheme_management    object\n",
              "extraction_type      object\n",
              "management           object\n",
              "payment              object\n",
              "water_quality        object\n",
              "quality_group        object\n",
              "quantity             object\n",
              "source               object\n",
              "waterpoint_type      object\n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JlVxg0BE1KZM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "bd81c92c-3f9d-4a5c-b6c8-5b1de9e745cb"
      },
      "source": [
        "columns_to_use = features.columns.to_list()\n",
        "columns_to_use"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['gps_height',\n",
              " 'basin',\n",
              " 'region_code',\n",
              " 'district_code',\n",
              " 'scheme_management',\n",
              " 'extraction_type',\n",
              " 'management',\n",
              " 'payment',\n",
              " 'water_quality',\n",
              " 'quality_group',\n",
              " 'quantity',\n",
              " 'source',\n",
              " 'waterpoint_type']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v4xWXK6LbrCe",
        "colab_type": "text"
      },
      "source": [
        "# Do train/validate/test split with the Tanzania Waterpumps data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Amxyx3xphbb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_features = pd.read_csv('../data/tanzania/train_features.csv')\n",
        "train_labels = pd.read_csv('../data/tanzania/train_labels.csv')\n",
        "test_features = pd.read_csv('../data/tanzania/test_features.csv')\n",
        "sample_submission = pd.read_csv('../data/tanzania/sample_submission.csv')\n",
        "\n",
        "X_train = train_features\n",
        "y_train = train_labels['status_group']\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_train, y_train, train_size = 0.80, stratify = y_train, random_state = 69\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "843fJiQEcvRi",
        "colab_type": "text"
      },
      "source": [
        "# Do one-hot encoding. (Remember it may not work with high cardinality categoricals.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Uq2OZog1b9t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "f101e4e1-2fb5-43fe-bf59-013b4f8efbfc"
      },
      "source": [
        "cats = X_train[columns_to_use].select_dtypes('object').columns.to_list()\n",
        "cats"
      ],
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['basin',\n",
              " 'scheme_management',\n",
              " 'extraction_type',\n",
              " 'management',\n",
              " 'payment',\n",
              " 'water_quality',\n",
              " 'quality_group',\n",
              " 'quantity',\n",
              " 'source',\n",
              " 'waterpoint_type']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yp7LFDj213v9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cats = X_train[cats].columns[X_train[cats].nunique() < 25].tolist()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AaWsH72tSfrr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        },
        "outputId": "1881dddc-24b7-41d3-c259-abd69cd117be"
      },
      "source": [
        "X_train[cats].nunique()"
      ],
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "basin                 9\n",
              "scheme_management    12\n",
              "extraction_type      18\n",
              "management           12\n",
              "payment               7\n",
              "water_quality         8\n",
              "quality_group         6\n",
              "quantity              5\n",
              "source               10\n",
              "waterpoint_type       7\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aF8nVnYU2KQ_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 327
        },
        "outputId": "a52e0b75-0f9c-4716-8059-6d677816dd44"
      },
      "source": [
        "import category_encoders as ce \n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder\n",
        "import bisect \n",
        "\n",
        "# installer\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "\n",
        "# train on train installer\n",
        "X_train['installer'] = label_encoder.fit_transform(X_train['installer'].fillna(X_train['installer'].mode()[0]))\n",
        "\n",
        "# change classes to have other in there?\n",
        "classes = label_encoder.classes_.tolist()\n",
        "bisect.insort_left(classes, 'other')\n",
        "label_encoder.classes_ = classes\n",
        "\n",
        "# map validation data to change any unseen installers to 'other'\n",
        "X_val['installer'] = X_val['installer'].map(lambda s: 'other' if s not in label_encoder.classes_ else s)\n",
        "\n",
        "# tranform \n",
        "X_val['installer'] = label_encoder.transform(X_val['installer'])\n",
        "\n",
        "numeric_features = X_train[columns_to_use].select_dtypes(['number', 'bool']).columns.tolist()\n",
        "features = cats + numeric_features + ['installer']\n",
        "\n",
        "X_train_subset = X_train[features]\n",
        "X_val_subset = X_val[features]\n",
        "\n",
        "encoder = ce.OneHotEncoder(use_cat_names=True)\n",
        "X_train_encoded = encoder.fit_transform(X_train_subset)\n",
        "X_val_encoded = encoder.transform(X_val_subset)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train_encoded)\n",
        "X_val_scaled = scaler.transform(X_val_encoded)"
      ],
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:22: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IxZ1Kjfekfm3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 288
        },
        "outputId": "967277d5-fd1e-4aeb-ca2c-fc2f3a124bec"
      },
      "source": [
        "features"
      ],
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['basin',\n",
              " 'scheme_management',\n",
              " 'extraction_type',\n",
              " 'management',\n",
              " 'payment',\n",
              " 'water_quality',\n",
              " 'quality_group',\n",
              " 'quantity',\n",
              " 'source',\n",
              " 'waterpoint_type',\n",
              " 'gps_height',\n",
              " 'region_code',\n",
              " 'district_code',\n",
              " 'installer']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bv0jl1W5i2r-",
        "colab_type": "text"
      },
      "source": [
        "# Use scikit-learn for logistic regression."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZ8RFzAW23Y7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 56
        },
        "outputId": "2f06cd3a-f22c-46a0-fa5a-3a5c0a2d386c"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegressionCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.feature_selection import f_regression, SelectKBest\n",
        "import time\n",
        "\n",
        "y_int = y_train.map({'functional': 3, 'functional needs repair': 2, 'non functional': 1})\n",
        "\n",
        "start = time.time()\n",
        "\n",
        "model = RandomForestClassifier(n_jobs = -1, n_estimators = 1000)\n",
        "\n",
        "model.fit(X_train_scaled, y_train)\n",
        "\n",
        "print('score ', model.score(X_val_scaled, y_val))\n",
        "\n",
        "print('time ', (time.time() - start) / 60, ' mins')"
      ],
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "score  0.7697811447811448\n",
            "time  0.631817889213562  mins\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xfa1uLhZ3WYA",
        "colab_type": "text"
      },
      "source": [
        "### my first was: ***0.725***\n",
        "### second: 0.732"
      ]
    }
  ]
}